-- If jobs are running daily, it may make sense to avoid the scanning necessary to determine the max partition date. Instead, a static incremental range can be set and this data will be overwritten/inserted at every incremental run.

{% set partitions_to_replace = [
  'current_date()',
  'date_sub(current_date(), interval 1 day)'
] %}

--BigQuery does not cache wildcard queries that scan across sharded tables which means it's best to materialize the raw event data as a partitioned table so that future queries benefit from caching
{{
    config(
        materialized = 'incremental',
        incremental_strategy = 'insert_overwrite',
        partition_by={
        "field": "event_date_dt",
        "data_type": "date",
        }
    )
}}

with source as (
    select * 
    from {{ source('ga4', 'events') }}
    where cast(_table_suffix as int64) >= {{var('start_date')}}
    {% if is_incremental() %}
        -- recalculate yesterday + today
        and parse_date('%Y%m%d',_TABLE_SUFFIX) in ({{ partitions_to_replace | join(',') }})
    {% endif %}
),
renamed as (
    select 
        parse_date('%Y%m%d',event_date) as event_date_dt, 
        * 
        EXCEPT (event_date) -- remove event date to ensure usage of event_date_dt which is partitioned
    from source
)

select * from renamed
